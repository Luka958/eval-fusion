endpoints:
  - name: chat
    endpoint_type: llm/v1/chat
    model:
      provider: mlflow-model-serving
      name: custom_llm
      config:
        model_server_url: http://127.0.0.1:5000
