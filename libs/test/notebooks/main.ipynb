{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "121120c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_fusion_core.utils.loaders import load_evaluation_inputs\n",
    "from eval_fusion_test.settings import get_openai_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252211fb",
   "metadata": {},
   "source": [
    "## `ragas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ea944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_fusion_ragas.evaluator import RagasEvaluator\n",
    "from eval_fusion_ragas.metrics import RagasMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fecf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluator(input_count: int):\n",
    "    llm_settings, em_settings = get_openai_settings()\n",
    "    inputs = load_evaluation_inputs('../assets/amnesty_qa.json')\n",
    "    inputs = inputs[:input_count]\n",
    "\n",
    "    with RagasEvaluator(llm_settings, em_settings) as evaluator:\n",
    "        outputs = evaluator.evaluate(inputs, metrics=[RagasMetric.FAITHFULNESS])\n",
    "\n",
    "    for output in outputs:\n",
    "        for output_entry in output.output_entries:\n",
    "            print(output_entry, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad3f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_name='faithfulness' score=0.84 reason=None error=None time=44.40238550002687\n",
      "\n",
      "metric_name='faithfulness' score=0.5172413793103449 reason=None error=None time=61.594070750055835\n",
      "\n",
      "metric_name='faithfulness' score=0.42857142857142855 reason=None error=None time=43.207843584008515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_evaluator(3)  # 2.5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd7b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def a_test_evaluator(input_count: int):\n",
    "    llm_settings, em_settings = get_openai_settings()\n",
    "    inputs = load_evaluation_inputs('../assets/amnesty_qa.json')\n",
    "    inputs = inputs[:input_count]\n",
    "\n",
    "    with RagasEvaluator(llm_settings, em_settings) as evaluator:\n",
    "        outputs = await evaluator.a_evaluate(inputs, metrics=[RagasMetric.FAITHFULNESS])\n",
    "\n",
    "    for output in outputs:\n",
    "        for output_entry in output.output_entries:\n",
    "            print(output_entry, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436ceb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_name='faithfulness' score=0.68 reason=None error=None time=33.963236584095284\n",
      "\n",
      "metric_name='faithfulness' score=0.041666666666666664 reason=None error=None time=34.28584862500429\n",
      "\n",
      "metric_name='faithfulness' score=0.3076923076923077 reason=None error=None time=19.234456334030256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await a_test_evaluator(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4813415d",
   "metadata": {},
   "source": [
    "## `deepeval`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ac71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_fusion_deepeval.evaluator import DeepEvalEvaluator\n",
    "from eval_fusion_deepeval.metrics import DeepEvalMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be549458",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def a_test_evaluator(input_count: int):\n",
    "    llm_settings, _ = get_openai_settings()\n",
    "    inputs = load_evaluation_inputs('../assets/amnesty_qa.json')\n",
    "    inputs = inputs[:input_count]\n",
    "\n",
    "    with DeepEvalEvaluator(llm_settings) as evaluator:\n",
    "        outputs = await evaluator.a_evaluate(\n",
    "            inputs, metrics=[DeepEvalMetric.FAITHFULNESS]\n",
    "        )\n",
    "\n",
    "    for output in outputs:\n",
    "        for output_entry in output.output_entries:\n",
    "            print(output_entry, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "515b5c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_name='Faithfulness' score=1.0 reason='The score is 1.00 because there are no contradictions, indicating full alignment between the actual output and the retrieval context. Great job!' error=None time=12.18744883290492\n",
      "\n",
      "metric_name='Faithfulness' score=1.0 reason='The score is 1.00 because there are no contradictions present, indicating that the actual output aligns perfectly with the retrieval context.' error=None time=13.545768999960274\n",
      "\n",
      "metric_name='Faithfulness' score=1.0 reason='The score is 0.92 because although the actual output asserts that ConocoPhillips Company is among the largest GHG emitters, this company is not referenced in the retrieval context, leading to a minor inconsistency.' error=None time=11.912813208065927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await a_test_evaluator(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a06ae5",
   "metadata": {},
   "source": [
    "## `arize-phoenix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d8db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_fusion_phoenix.evaluator import PhoenixEvaluator\n",
    "from eval_fusion_phoenix.metrics import PhoenixMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b801c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def a_test_evaluator(input_count: int):\n",
    "    llm_settings, _ = get_openai_settings()\n",
    "    inputs = load_evaluation_inputs('../assets/amnesty_qa.json')\n",
    "    inputs = inputs[:input_count]\n",
    "\n",
    "    with PhoenixEvaluator(llm_settings) as evaluator:\n",
    "        outputs = await evaluator.a_evaluate(inputs, metrics=[PhoenixMetric.RELEVANCE])\n",
    "\n",
    "    for output in outputs:\n",
    "        for output_entry in output.output_entries:\n",
    "            print(output_entry, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80329188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_name='relevance' score=1.0 reason='To determine if the reference text contains information relevant to the question regarding the global implications of the USA Supreme Court ruling on abortion, we can analyze the content step by step:\\n\\n1. **Identify the Question**: The question asks about the global implications of a specific ruling by the USA Supreme Court regarding abortion.\\n\\n2. **Examine the Reference Text**: The reference text outlines the Supreme Court ruling, its immediate impact on abortion access in the USA, and explicitly mentions its global implications.\\n\\n3. **Global Context in the Reference Text**: \\n   - It states that the ruling has had effects beyond national borders, indicating the USA\\'s geopolitical and cultural influence.\\n   - It mentions reactions from organizations and activists worldwide who fear that the ruling could encourage anti-abortion legislation in other countries.\\n   - There are observations about the stalling of progressive law reform in African countries due to this ruling, showcasing a direct connection between the ruling and its global implications.\\n\\n4. **Impact on International Organizations**: The reference text notes that international organizations working on reproductive rights may shift their advocacy and funding strategies in response to the ruling, which speaks directly to how such decisions can have widespread global effects.\\n\\n5. **Overall Assessment**: The reference text provides concrete examples and details that illustrate the ways in which the USA Supreme Court ruling on abortion could affect policies, social attitudes, and legal frameworks in other countries, thereby addressing the specific query about global implications.\\n\\nBased on this reasoning, the reference text clearly provides information that can assist in answering the question.\\n\\nLABEL: \"relevant\"' error=None time=6.279497167095542\n",
      "\n",
      "metric_name='relevance' score=1.0 reason='The question asks for the main contributors to greenhouse gas (GHG) emissions and their role in global warming, specifically referencing the Carbon Majors database. To determine if the reference text provides relevant information, I will look for:\\n\\n1. Identification of specific companies mentioned in the context of GHG emissions.\\n2. Information about their contributions to GHG emissions and their impact on global warming.\\n3. Direct references to the Carbon Majors database, as it is crucial for answering the question.\\n\\nUpon reviewing the reference text, I notice that it explicitly states that the Carbon Majors database identifies a small group of companies responsible for the majority of global GHG emissions, providing important context. It mentions major oil and gas producers, coal mining companies, and lists specific companies such as ExxonMobil, Chevron, Peabody, Pemex, and Petr√≥leos de Venezuela, S.A. as some of the main contributors.\\n\\nFurthermore, the text details that these 100 identified companies account for a substantial percentage (71%) of global GHG emissions since 1988, highlighting their significant role in global warming. This aligns directly with what the question is asking.\\n\\nGiven these points, it is clear that the reference text contains relevant information to answer the question regarding the specific companies and their contributions to GHG emissions.\\n\\nLABEL: relevant' error=None time=5.134803166845813\n",
      "\n",
      "metric_name='relevance' score=1.0 reason='To determine if the reference text contains information relevant to the question about which private companies in the Americas are the largest GHG emitters according to the Carbon Majors database, we can follow these steps:\\n\\n1. **Identify the Subject Matter**: The question specifically asks about the largest private companies in the Americas that emit greenhouse gases, using the Carbon Majors database as a source.\\n\\n2. **Examine the Reference Text**: The reference text discusses greenhouse gas emissions and mentions that private companies in the Americas contribute significantly to these emissions.\\n\\n3. **Look for Specific Companies**: The text lists some of the largest emitters among private companies in the Americas, specifically naming ExxonMobil, Chevron, and Peabody as prominent producers of emissions during the referenced period.\\n\\n4. **Consider the Context**: This information from the reference text correlates directly with the question, as it answers specifically which private companies are identified as the largest GHG emitters in the Americas.\\n\\n5. **Check for Completeness**: The reference text provides the names of the companies and categorizes them correctly as private firms, thus fulfilling the requirements of the question.\\n\\nSince the reference text not only discusses the role of private companies in greenhouse gas emissions but also provides specific names of the largest emitters, it clearly contains information that helps answer the question.\\n\\nLABEL: \"relevant\"' error=None time=7.056254249997437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await a_test_evaluator(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88490303",
   "metadata": {},
   "source": [
    "## `llama-index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a6ce907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_fusion_llama_index.evaluator import LlamaIndexEvaluator\n",
    "from eval_fusion_llama_index.metrics import LlamaIndexMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f440267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluator(input_count: int):\n",
    "    llm_settings, em_settings = get_openai_settings()\n",
    "    inputs = load_evaluation_inputs('../assets/amnesty_qa.json')\n",
    "    inputs = inputs[:input_count]\n",
    "\n",
    "    with LlamaIndexEvaluator(llm_settings, em_settings) as evaluator:\n",
    "        outputs = evaluator.evaluate(inputs, metrics=[LlamaIndexMetric.FAITHFULNESS])\n",
    "\n",
    "    for output in outputs:\n",
    "        for output_entry in output.output_entries:\n",
    "            print(output_entry, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c544d882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_name='faithfulness' score=1.0 reason='YES' error=None time=1.083593624876812\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_evaluator(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6e052e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def a_test_evaluator(input_count: int):\n",
    "    llm_settings, em_settings = get_openai_settings()\n",
    "    inputs = load_evaluation_inputs('../assets/amnesty_qa.json')\n",
    "    inputs = inputs[:input_count]\n",
    "\n",
    "    with LlamaIndexEvaluator(llm_settings, em_settings) as evaluator:\n",
    "        outputs = await evaluator.a_evaluate(\n",
    "            inputs, metrics=[LlamaIndexMetric.FAITHFULNESS]\n",
    "        )\n",
    "\n",
    "    for output in outputs:\n",
    "        for output_entry in output.output_entries:\n",
    "            print(output_entry, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1c98531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_name='faithfulness' score=1.0 reason='YES' error=None time=0.7645129591692239\n",
      "\n",
      "metric_name='faithfulness' score=1.0 reason='YES' error=None time=0.6694967080838978\n",
      "\n",
      "metric_name='faithfulness' score=0.0 reason='NO' error=None time=0.6710254161152989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await a_test_evaluator(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e9042d",
   "metadata": {},
   "source": [
    "## `tonic-validate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d389cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_fusion_tonic_validate.evaluator import TonicValidateEvaluator\n",
    "from eval_fusion_tonic_validate.metrics import TonicValidateMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71acad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluator(input_count: int):\n",
    "    llm_settings, _ = get_openai_settings()\n",
    "    inputs = load_evaluation_inputs('../assets/amnesty_qa.json')\n",
    "    inputs = inputs[:input_count]\n",
    "\n",
    "    with TonicValidateEvaluator(llm_settings) as evaluator:\n",
    "        outputs = evaluator.evaluate(\n",
    "            inputs, metrics=[TonicValidateMetric.ANSWER_CONSISTENCY]\n",
    "        )\n",
    "\n",
    "    for output in outputs:\n",
    "        for output_entry in output.output_entries:\n",
    "            print(output_entry, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62741b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring responses: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_name='answer_consistency' score=1.0 reason=None error=None time=6.0304533750750124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_evaluator(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86fd420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def a_test_evaluator(input_count: int):\n",
    "    llm_settings, _ = get_openai_settings()\n",
    "    inputs = load_evaluation_inputs('../assets/amnesty_qa.json')\n",
    "    inputs = inputs[:input_count]\n",
    "\n",
    "    with TonicValidateEvaluator(llm_settings) as evaluator:\n",
    "        outputs = await evaluator.a_evaluate(\n",
    "            inputs, metrics=[TonicValidateMetric.ANSWER_CONSISTENCY]\n",
    "        )\n",
    "\n",
    "    for output in outputs:\n",
    "        for output_entry in output.output_entries:\n",
    "            print(output_entry, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f08480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Scoring responses: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.19s/it]\n",
      "\n",
      "Scoring responses: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:09<00:00,  9.49s/it]\n",
      "Scoring responses: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:15<00:00, 15.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_name='answer_consistency' score=1.0 reason=None error=None time=7.912690416909754\n",
      "\n",
      "metric_name='answer_consistency' score=0.6923076923076923 reason=None error=None time=16.03793100011535\n",
      "\n",
      "metric_name='answer_consistency' score=0.4166666666666667 reason=None error=None time=10.303196958033368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await a_test_evaluator(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4374dfb",
   "metadata": {},
   "source": [
    "## `ragchecker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3506f945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 19:05:44.317000 93633 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: scikit-learn-intelex not installed, sklearn acceleration for the RepC checker is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from eval_fusion_ragchecker.evaluator import RagCheckerEvaluator\n",
    "from eval_fusion_ragchecker.metrics import RagCheckerMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "591771e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluator(input_count: int):\n",
    "    llm_settings, _ = get_openai_settings()\n",
    "    inputs = load_evaluation_inputs('../assets/amnesty_qa.json')\n",
    "    inputs = inputs[:input_count]\n",
    "\n",
    "    with RagCheckerEvaluator(llm_settings) as evaluator:\n",
    "        outputs = evaluator.evaluate(inputs, metrics=[RagCheckerMetric.FAITHFULNESS])\n",
    "\n",
    "    for output in outputs:\n",
    "        for output_entry in output.output_entries:\n",
    "            print(output_entry, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e74bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-26 19:02:33.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mragchecker.evaluator\u001b[0m:\u001b[36mextract_claims\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mExtracting claims for response of 1 RAG results.\u001b[0m\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:08<00:00,  8.46s/it]\n",
      "\u001b[32m2025-07-26 19:02:42.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mragchecker.evaluator\u001b[0m:\u001b[36mcheck_claims\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mChecking retrieved2response for 1 RAG results.\u001b[0m\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_name='faithfulness' score=71.4 reason=None error=None time=19.43028845777735\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_evaluator(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaf86bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def a_test_evaluator(input_count: int):\n",
    "    llm_settings, _ = get_openai_settings()\n",
    "    inputs = load_evaluation_inputs('../assets/amnesty_qa.json')\n",
    "    inputs = inputs[:input_count]\n",
    "\n",
    "    with RagCheckerEvaluator(llm_settings) as evaluator:\n",
    "        outputs = await evaluator.a_evaluate(\n",
    "            inputs, metrics=[RagCheckerMetric.FAITHFULNESS]\n",
    "        )\n",
    "\n",
    "    for output in outputs:\n",
    "        for output_entry in output.output_entries:\n",
    "            print(output_entry, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62259a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-26 19:05:45.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mragchecker.evaluator\u001b[0m:\u001b[36mextract_claims\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mExtracting claims for response of 1 RAG results.\u001b[0m\n",
      "\u001b[32m2025-07-26 19:05:45.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mragchecker.evaluator\u001b[0m:\u001b[36mextract_claims\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mExtracting claims for response of 1 RAG results.\u001b[0m\n",
      "\u001b[32m2025-07-26 19:05:45.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mragchecker.evaluator\u001b[0m:\u001b[36mextract_claims\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mExtracting claims for response of 1 RAG results.\u001b[0m\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.02s/it]\n",
      "\u001b[32m2025-07-26 19:05:52.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mragchecker.evaluator\u001b[0m:\u001b[36mcheck_claims\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mChecking retrieved2response for 1 RAG results.\u001b[0m\n",
      " 11%|‚ñà         | 1/9 [00:01<00:08,  1.12s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.14s/it]\n",
      "\u001b[32m2025-07-26 19:05:53.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mragchecker.evaluator\u001b[0m:\u001b[36mcheck_claims\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mChecking retrieved2response for 1 RAG results.\u001b[0m\n",
      "\n",
      " 22%|‚ñà‚ñà‚ñè       | 2/9 [00:01<00:06,  1.14it/s]\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:02<00:04,  1.32it/s]\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:03<00:03,  1.28it/s]\n",
      "\u001b[A\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:04<00:02,  1.30it/s]\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:05<00:01,  1.27it/s]\n",
      "\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:12<00:00, 12.70s/it]\n",
      "\u001b[32m2025-07-26 19:05:58.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mragchecker.evaluator\u001b[0m:\u001b[36mcheck_claims\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mChecking retrieved2response for 1 RAG results.\u001b[0m\n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:07<00:00,  1.24it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:10<00:00,  1.43it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:10<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_name='faithfulness' score=66.7 reason=None error=None time=13.306292458903044\n",
      "\n",
      "metric_name='faithfulness' score=40.0 reason=None error=None time=23.13434824999422\n",
      "\n",
      "metric_name='faithfulness' score=80.0 reason=None error=None time=17.682423416990787\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "await a_test_evaluator(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval-fusion-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
